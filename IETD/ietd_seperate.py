import os
import glob
import chardet
import pandas as pd
import numpy as np
from datetime import timedelta


def infer_dt_minutes(index: pd.DatetimeIndex) -> float:
    """
    DatetimeIndexì—ì„œ ëŒ€í‘œ ì‹œê°„ ê°„ê²©(ë¶„)ì„ ì¶”ì •
    - ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚˜ëŠ” ì‹œê°„ ê°„ê²©ì„ ì‚¬ìš© (mode)
    """
    diffs = index.to_series().diff().dropna()
    dt = diffs.mode().iloc[0]
    return dt.total_seconds() / 60.0


def split_rain_events_ietd(
    df: pd.DataFrame,
    rain_col: str = "rf",  # ê°•ìš° ì»¬ëŸ¼ëª…
    ietd_hours: float = 6.0,  # IETD (ì‹œê°„ ë‹¨ìœ„)
    dt_minutes: float | None = 10.0,  # ìë£Œ ì‹œê°„ ê°„ê²©(ë¶„), Noneì´ë©´ ìë™ ì¶”ì •
    rain_threshold: float = 0.0,  # ìœ íš¨ ê°•ìš° ì„ê³„ê°’ (mm/Î”t)
    min_event_depth: float = 0.0,  # ìµœì†Œ ì‚¬ìƒ ëˆ„ì ê°•ìš°(mm) í•„í„°
    include_dry_tail: bool = True,  # IETD ì´í•˜ ë¬´ê°•ìš° êµ¬ê°„ì„ ì´ë²¤íŠ¸ ê¼¬ë¦¬ë¡œ í¬í•¨í• ì§€ ì—¬ë¶€
) -> pd.DataFrame:
    """
    IETD ê¸°ë²•ì— ì˜í•œ ê°•ìš°ì‚¬ìƒ ë¶„ë¦¬.
    - df: DatetimeIndexë¥¼ ê°€ì§„ DataFrame (ì‹œê°„ ì˜¤ë¦„ì°¨ìˆœ ê°€ì •, ì•„ë‹ˆë©´ ì´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì •ë ¬)
    - rain_col: ê°•ìš°(mm) ì»¬ëŸ¼ëª…
    - ietd_hours: IETD (ì‹œê°„)
    - dt_minutes: ì‹œê°„ ê°„ê²©(ë¶„). Noneì´ë©´ indexë¡œë¶€í„° ì¶”ì •
    - rain_threshold: ì´ ê°’ ì´ìƒì´ë©´ 'ê°•ìš° ìˆìŒ'ìœ¼ë¡œ ê°„ì£¼
    - min_event_depth: ì´ ê°’ ë¯¸ë§Œì¸ ì´ë²¤íŠ¸ëŠ” ì œê±° (event_idë¥¼ NaNìœ¼ë¡œ ì²˜ë¦¬)
    - include_dry_tail:
        True  -> IETD ì´í•˜ì˜ ë¬´ê°•ìš° êµ¬ê°„ë„ ì´ë²¤íŠ¸ì— í¬í•¨ (ìˆ˜ìœ„ ë°˜ì‘ ê³ ë ¤í•  ë•Œ ìœ ìš©)
        False -> ê°•ìš°ê°€ ìˆëŠ” ì‹œì ì—ë§Œ event_id ë¶€ì—¬
    ë°˜í™˜:
        event_id ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame
    """
    if not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("DataFrame indexëŠ” DatetimeIndexì—¬ì•¼ í•©ë‹ˆë‹¤.")

    df = df.sort_index().copy()

    if dt_minutes is None:
        dt_minutes = infer_dt_minutes(df.index)

    # IETDë¥¼ time-step ê°œìˆ˜ë¡œ ë³€í™˜ (ì˜ˆ: 6ì‹œê°„, 10ë¶„ìë£Œ -> 36 step)
    ietd_minutes = ietd_hours * 60.0
    ietd_steps = int(np.ceil(ietd_minutes / dt_minutes))

    rain = df[rain_col].fillna(0.0).values
    n = len(df)

    event_ids = np.full(n, np.nan, dtype=float)

    event_id = 0
    dry_steps = ietd_steps  # ì²˜ìŒì—ëŠ” "ì¶©ë¶„íˆ ê±´ì¡°í•˜ë‹¤" ê°€ì •

    for i in range(n):
        r = rain[i]
        wet = r >= rain_threshold

        if wet:
            # IETD ì´ìƒ ê±´ê¸° í›„ ì²˜ìŒ ë¹„ê°€ ë‚´ë¦¬ë©´ ìƒˆë¡œìš´ ì´ë²¤íŠ¸ ì‹œì‘
            if dry_steps >= ietd_steps:
                event_id += 1
            event_ids[i] = event_id
            dry_steps = 0

        else:
            # ë¹„ê°€ ì•ˆ ì˜¬ ë•Œ
            if include_dry_tail and event_id > 0 and dry_steps < ietd_steps:
                # ì•„ì§ IETDì— ë„ë‹¬í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ì´ì „ ì´ë²¤íŠ¸ ê¼¬ë¦¬ë¡œ í¬í•¨
                event_ids[i] = event_id
                dry_steps += 1
            else:
                # ì™„ì „íˆ ê±´ê¸° or ì´ë²¤íŠ¸ ì—†ìŒ
                dry_steps = min(dry_steps + 1, ietd_steps)

    df["event_id"] = event_ids

    # ìµœì†Œ ì´ë²¤íŠ¸ ê°•ìš°ëŸ‰ í•„í„°ë§ (ë„ˆë¬´ ì‘ì€ ì´ë²¤íŠ¸ ì œê±°)
    if min_event_depth > 0:
        valid_ids = []
        for eid, group in df.groupby("event_id", dropna=True):
            depth = group[rain_col].sum()
            if depth >= min_event_depth:
                valid_ids.append(eid)

        df.loc[~df["event_id"].isin(valid_ids), "event_id"] = np.nan

    return df


def filter_events_by_water_level(
    events, water_level_data, threshold_level=2.5, time_lag=12
):
    """
    ê´€ì‹¬ë‹¨ê³„ ìˆ˜ìœ„ ì´ìƒ ì‚¬ìƒë§Œ í•„í„°ë§

    Parameters:
    -----------
    events : DataFrame
        ë¶„ë¦¬ëœ ê°•ìš° ì‚¬ìƒ
    water_level_data : DataFrame
        columns: ['datetime', 'water_level']
    threshold_level : float
        ê´€ì‹¬ë‹¨ê³„ ìˆ˜ìœ„ (m)
    time_lag : int
        ìˆ˜ìœ„ ì‘ë‹µ ì‹œê°„ (ì‹œê°„)
    """

    wl_df = water_level_data.copy()
    wl_df["datetime"] = pd.to_datetime(wl_df["datetime"])

    valid_events = []

    for idx, event in events.iterrows():
        # ë¶„ì„ ê¸°ê°„ ì„¤ì •
        analysis_start = event["start_time"] - timedelta(hours=1)
        analysis_end = event["end_time"] + timedelta(hours=time_lag)

        # í•´ë‹¹ ê¸°ê°„ ìˆ˜ìœ„ ì¶”ì¶œ
        mask = (wl_df["datetime"] >= analysis_start) & (
            wl_df["datetime"] <= analysis_end
        )
        period_wl = wl_df.loc[mask, "water_level"]

        if len(period_wl) > 0:
            max_wl = period_wl.max()

            # ê´€ì‹¬ë‹¨ê³„ ì´ìƒì¸ ê²½ìš°ë§Œ ì„ íƒ
            if max_wl >= threshold_level:
                event_dict = event.to_dict()
                event_dict["max_water_level"] = max_wl
                event_dict["water_level_rise"] = max_wl - period_wl.iloc[0]
                valid_events.append(event_dict)

    return pd.DataFrame(valid_events)


def summarize_rain_events(
    df: pd.DataFrame, rain_col: str = "rf", event_col: str = "event_id"
) -> pd.DataFrame:
    """
    event_idê°€ ë¶™ì€ DataFrameì—ì„œ ì´ë²¤íŠ¸ë³„ ìš”ì•½ í†µê³„ ê³„ì‚°
    - ì‹œì‘ì‹œê°, ì¢…ë£Œì‹œê°, ì§€ì†ì‹œê°„(ë¶„/ì‹œê°„), ì´ê°•ìš°(mm), ìµœëŒ€ê°•ìš°ê°•ë„(mm/Î”t) ë“±
    """
    out = []

    for eid, group in df.groupby(event_col, dropna=True):
        start = group.index[0]
        end = group.index[-1]
        duration_min = (end - start).total_seconds() / 60.0
        total_rf = group[rain_col].sum()
        max_rf = group[rain_col].max()
        steps = len(group)

        out.append(
            {
                "event_id": eid,
                "start": start,
                "end": end,
                "duration_min": duration_min,
                "duration_hr": duration_min / 60.0,
                "n_steps": steps,
                "total_rf_mm": total_rf,
                "max_rf_mm_per_step": max_rf,
            }
        )

    return pd.DataFrame(out).set_index("event_id").sort_index()


#------------------------------------------------------------------------------------------------------

def detect_encoding(file_path, n_lines=5000):
    with open(file_path, 'rb') as f:
        raw = f.read(n_lines)
    return chardet.detect(raw)['encoding']


def cut_interest_level_instants(df: pd.DataFrame, wl_col: str, threshold: float) -> pd.DataFrame:
    """
    ë‹¨ì¼ ìˆ˜ìœ„ ì»¬ëŸ¼(wl_col)ì— ëŒ€í•´
    ê´€ì‹¬ìˆ˜ìœ„(threshold) ì´ìƒì¸ ì‹œì (row)ë§Œ ë‚¨ê¸°ëŠ” í•¨ìˆ˜.
    ë¬¸ìì—´ë¡œ ì½íŒ ìˆ˜ìœ„ë„ ìˆ«ìë¡œ ë³€í™˜í•´ì„œ ë¹„êµ.
    """

    # 1) ìˆ˜ìœ„ ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ìºìŠ¤íŒ… í›„, ì‰¼í‘œ ì œê±° ë“± ì „ì²˜ë¦¬
    s = df[wl_col].astype(str).str.replace(',', '', regex=False).str.strip()

    # 2) ìˆ«ìë¡œ ë³€í™˜ (ë³€í™˜ ì•ˆ ë˜ëŠ” ê°’ì€ NaNìœ¼ë¡œ ì²˜ë¦¬)
    wl_numeric = pd.to_numeric(s, errors='coerce')

    # (ì„ íƒ) NaNì´ ìˆìœ¼ë©´ ë¡œê·¸ ì°ì–´ì„œ í™•ì¸
    if wl_numeric.isna().any():
        print(f"[WARN] {wl_col} ì»¬ëŸ¼ì—ì„œ ìˆ«ìë¡œ ë³€í™˜ ì•ˆ ëœ ê°’ì´ ìˆìŠµë‹ˆë‹¤. (NaN ê°œìˆ˜: {wl_numeric.isna().sum()})")

    # 3) ì¡°ê±´ ë§ˆìŠ¤í¬ ìƒì„± (ìˆ«ì ê¸°ì¤€ ë¹„êµ)
    cond = wl_numeric >= float(threshold)

    # 4) ì¡°ê±´ ë§Œì¡± rowë§Œ í•„í„°ë§
    df_cut = df[cond].copy()

    # (ì„ íƒ) í•„í„°ë§ëœ DFì˜ í•´ë‹¹ ìˆ˜ìœ„ ì»¬ëŸ¼ì€ ìˆ«ìí˜•ìœ¼ë¡œ ë®ì–´ì“°ê¸°
    df_cut[wl_col] = wl_numeric[cond]

    return df_cut


def cut_interest_level_window6h(
    df: pd.DataFrame,
    wl_col: str,
    threshold: float,
    window_hours: float = 6.0,
    pre_hours: float = 2.0,
) -> pd.DataFrame | None:
    """
    1) wl_colì´ threshold ì´ìƒì¸ êµ¬ê°„ì´ ìˆëŠ”ì§€ í™•ì¸
    2) ê·¸ ì¤‘ í”¼í¬ ìˆ˜ìœ„ ì‹œê°(peak)ì„ anchorë¡œ ì¡ê³ 
    3) ì• pre_hours, ë’¤ (window_hours - pre_hours) ë§Œí¼ ë¶™ì—¬ì„œ
       ì´ window_hours ì‹œê°„ ê¸¸ì´ì˜ êµ¬ê°„ì„ ì˜ë¼ ë°˜í™˜.

    - df: í•œ MIET ê°•ìš°ì‚¬ìƒ CSV (time ì»¬ëŸ¼ í¬í•¨)
    - wl_col: ìˆ˜ìœ„ ì»¬ëŸ¼ ì´ë¦„
    - threshold: ê´€ì‹¬ìˆ˜ìœ„
    """

    if "time" not in df.columns:
        raise ValueError("DataFrameì— 'time' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # 1) ì‹œê°„ íŒŒì‹± + ì¸ë±ìŠ¤ë¡œ ì„¤ì •
    df = df.copy()
    df["time"] = pd.to_datetime(df["time"], errors="coerce")
    df = df.set_index("time").sort_index()

    # 2) ìˆ˜ìœ„ ì»¬ëŸ¼ ìˆ«ìë¡œ ë³€í™˜
    s = df[wl_col].astype(str).str.replace(",", "", regex=False).str.strip()
    wl_numeric = pd.to_numeric(s, errors="coerce")

    cond = wl_numeric >= float(threshold)

    if not cond.any():
        # ê´€ì‹¬ìˆ˜ìœ„ ë„ë‹¬ ì•ˆ í•œ ê°•ìš°ì‚¬ìƒ
        return None

    # 3) ê´€ì‹¬ìˆ˜ìœ„ ì´ìƒ êµ¬ê°„ì—ì„œ í”¼í¬ ì°¾ê¸°
    wl_exceed = wl_numeric[cond]
    peak_idx = wl_exceed.idxmax()      # DatetimeIndex (í”¼í¬ ì‹œê°)
    peak_time = peak_idx

    # 4) 6ì‹œê°„ ìœˆë„ìš° ê³„ì‚°
    post_hours = window_hours - pre_hours
    ideal_start = peak_time - pd.Timedelta(hours=pre_hours)
    ideal_end   = peak_time + pd.Timedelta(hours=post_hours)

    # 5) ì´ë²¤íŠ¸(ì´ íŒŒì¼) ì „ì²´ ì‹œê°„ ë²”ìœ„
    event_start = df.index.min()
    event_end   = df.index.max()

    # ë¨¼ì € startë¥¼ ì´ë²¤íŠ¸ ë²”ìœ„ ì•ˆìœ¼ë¡œ
    start = max(ideal_start, event_start)
    end   = start + pd.Timedelta(hours=window_hours)

    # endê°€ ì´ë²¤íŠ¸ ëì„ ë„˜ìœ¼ë©´ ë’¤ì—ì„œ ë‹¤ì‹œ ë§ì¶°ì¤Œ
    if end > event_end:
        end = event_end
        start = end - pd.Timedelta(hours=window_hours)

    # ì‹¤ì œ ê¸¸ì´ê°€ ì—¬ì „íˆ ë¶€ì¡±í•˜ë©´ ìŠ¤í‚µ
    actual_hours = (end - start).total_seconds() / 3600.0
    if actual_hours < window_hours - 1e-6:
        return None

    # 6) ìµœì¢… ìŠ¬ë¼ì´ì‹±
    df_win = df.loc[start:end].copy()

    # ìˆ˜ìœ„ ì»¬ëŸ¼ì€ ìˆ«ìí˜•ìœ¼ë¡œ ë®ì–´ì“°ê¸° (ì„ íƒ)
    df_win[wl_col] = wl_numeric.loc[df_win.index]

    # time ì»¬ëŸ¼ ë‹¤ì‹œ ë„£ì–´ë‘ë©´ CSVë¡œ ì €ì¥í•˜ê¸° í¸í•¨
    df_win = df_win.reset_index().rename(columns={"time": "time"})

    return df_win


def process_miet_dir_to_ietd(
        miet_dir: str,
        out_dir: str,
        wl_col: str,
        threshold: float,
        skip_empty: bool = True
    ):
    os.makedirs(out_dir, exist_ok=True)

    for fname in os.listdir(miet_dir):
        if not fname.lower().endswith(".csv"):
            continue

        in_path = os.path.join(miet_dir, fname)

        # ğŸ” ìë™ ì¸ì½”ë”© ê°ì§€
        encoding = detect_encoding(in_path)
        print(f"[INFO] {fname} detected encoding = {encoding}")

        # CSV ë¡œë“œ
        df = pd.read_csv(in_path, encoding=encoding)

        # time íŒŒì‹±
        if "time" in df.columns:
            df["time"] = pd.to_datetime(df["time"], errors="coerce")

        # í•„í„°ë§
        df_cut = cut_interest_level_instants(df, wl_col=wl_col, threshold=threshold)

        if df_cut.empty and skip_empty:
            print(f"[SKIP] {fname} : ê´€ì‹¬ìˆ˜ìœ„ ë„ë‹¬ ì—†ìŒ")
            continue

        out_path = os.path.join(out_dir, fname)
        df_cut.to_csv(out_path, index=False, encoding="utf-8-sig")
        print(f"[SAVE] {out_path} rows={len(df_cut)}")

    
def process_miet_dir_to_ietd_window6h(
    miet_dir: str,
    out_dir: str,
    wl_col: str,
    threshold: float,
    window_hours: float = 6.0,
    pre_hours: float = 2.0,
    skip_empty: bool = True,
    ):
    """
    MIET í´ë”(miet_dir) ì•ˆì˜ ê° ê°•ìš°ì‚¬ìƒ CSVì— ëŒ€í•´:
    - ê´€ì‹¬ìˆ˜ìœ„(threshold)ë¥¼ ë„˜ëŠ” ì´ë²¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°
    - í”¼í¬ ì‹œê° ê¸°ì¤€ 6ì‹œê°„(window_hours) êµ¬ê°„ìœ¼ë¡œ ì˜ë¼ì„œ out_dirì— ì €ì¥
    """

    os.makedirs(out_dir, exist_ok=True)

    for fname in os.listdir(miet_dir):
        if not fname.lower().endswith(".csv"):
            continue

        in_path = os.path.join(miet_dir, fname)

        # ğŸ” ìë™ ì¸ì½”ë”© ê°ì§€
        encoding = detect_encoding(in_path)
        print(f"[INFO] {fname} detected encoding = {encoding}")

        # CSV ë¡œë“œ
        df = pd.read_csv(in_path, encoding=encoding)

        # 6ì‹œê°„ ìœˆë„ìš° ìë¥´ê¸°
        df_win = cut_interest_level_window6h(
            df=df,
            wl_col=wl_col,
            threshold=threshold,
            window_hours=window_hours,
            pre_hours=pre_hours,
        )

        if (df_win is None or df_win.empty) and skip_empty:
            print(f"[SKIP] {fname} : ê´€ì‹¬ìˆ˜ìœ„ ë„ë‹¬ ì—†ìŒ ë˜ëŠ” 6ì‹œê°„ ìœˆë„ìš° ìƒì„± ì‹¤íŒ¨")
            continue

        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ì›ë˜ ì´ë¦„ ê·¸ëŒ€ë¡œ ì“°ê±°ë‚˜, ì ‘ë¯¸ì–´ë¥¼ ë¶™ì—¬ë„ ë¨)
        out_path = os.path.join(out_dir, fname)
        df_win.to_csv(out_path, index=False, encoding="utf-8-sig")
        print(f"[SAVE] {out_path} rows={len(df_win)}")


if __name__ == "__main__":

    # ê¶ë‚´ = "gn", ëŒ€ê³¡ = "dg"
    station_type = "gn"

    miet_data = [86, 61, 80, 96, 92, 74, 62, 98, 99, 69, 95, 97]
    years = range(2014, 2025 + 1)

    # ì—°ë„ì™€ MIETë¥¼ 1:1ë¡œ ë§¤í•‘
    for year, MIET in zip(years, miet_data):

        # ê´€ì¸¡ì†Œ íƒ€ì…ì— ë”°ë¼ ì„¤ì • ë¶„ê¸°
        if station_type == "gn":   # ê¶ë‚´
            name = "ê¶ë‚´êµ"
            wl_col = "ì„±ë‚¨ì‹œ(ê¶ë‚´êµ)_WL"
            threshold = 2.0

        elif station_type == "dg":  # ëŒ€ê³¡
            name = "ëŒ€ê³¡êµ"
            wl_col = "ì„œìš¸ì‹œ(ëŒ€ê³¡êµ)_WL"
            threshold = 3.8

        else:
            # ê¸°ë³¸ê°’: ê¶ë‚´
            name = "ê¶ë‚´êµ"
            wl_col = "ì„±ë‚¨ì‹œ(ê¶ë‚´êµ)_WL"
            threshold = 2.0

        base_dir = ".."

        miet_gn_dir = os.path.join(base_dir, "MIET", f"{year} í•™ìŠµë°ì´í„° ê°•ìš°ì‚¬ìƒ({MIET})")

        ietd_gn_dir = os.path.join(base_dir, "IETD", f"{name} {year} í•™ìŠµë°ì´í„° ê´€ì‹¬ ê°•ìš°ì‚¬ìƒ({MIET})")

        # process_miet_dir_to_ietd(
        #     miet_dir=miet_gn_dir,
        #     out_dir=ietd_gn_dir,
        #     wl_col=wl_col,
        #     threshold=threshold
        # )

        process_miet_dir_to_ietd_window6h(
            miet_dir=miet_gn_dir,
            out_dir=ietd_gn_dir,
            wl_col=wl_col,
            threshold=threshold,
            window_hours=6.0,   # ì „ì²´ 6ì‹œê°„
            pre_hours=2.0,      # í”¼í¬ ì´ì „ 2h + ì´í›„ 4h
        )
